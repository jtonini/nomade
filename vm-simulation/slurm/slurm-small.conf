# NOMADE Simulation - Small Cluster
# Realistic heterogeneous cluster for demos and testing
#
# Node breakdown:
#   8 cpu-standard  (64 cores, 512 GB RAM, 1 TB local)
#   2 cpu-highmem   (64 cores, 1.5 TB RAM, 1 TB local)
#   8 gpu           (32 cores, 256 GB RAM, 4x A100-80GB, 2 TB local)
#
# Totals: 18 nodes | 1,184 cores | 32 GPUs | 7.5 TB RAM
# Shared storage: 100 TB (simulated)

ClusterName=nomade-small
SlurmctldHost=nomade-test

# Scheduling
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory

# Logging
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log
SlurmctldPidFile=/run/slurmctld.pid
SlurmdPidFile=/run/slurmd.pid

# Directories
StateSaveLocation=/var/spool/slurm/ctld
SlurmdSpoolDir=/var/spool/slurm/d

# Users
SlurmUser=slurm
SlurmdUser=root

# Timeouts
SlurmctldTimeout=300
SlurmdTimeout=300
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0

# Authentication
AuthType=auth/munge
CryptoType=crypto/munge

# GPU support
GresTypes=gpu

# Accounting
AccountingStorageType=accounting_storage/none
JobAcctGatherType=jobacct_gather/none

#------------------------------------------------------------------------------
# Node Definitions
#------------------------------------------------------------------------------

# CPU Standard: 64 cores, 512 GB RAM
NodeName=cpu[01-08] CPUs=64 RealMemory=524288 State=UNKNOWN

# CPU High-Memory: 64 cores, 1.5 TB RAM
NodeName=highmem[01-02] CPUs=64 RealMemory=1572864 State=UNKNOWN

# GPU: 32 cores, 256 GB RAM, 4x NVIDIA A100-80GB
NodeName=gpu[01-08] CPUs=32 RealMemory=262144 Gres=gpu:a100:4 State=UNKNOWN

#------------------------------------------------------------------------------
# Partitions
#------------------------------------------------------------------------------

PartitionName=standard Nodes=cpu[01-08] Default=YES MaxTime=7-00:00:00 State=UP
PartitionName=highmem  Nodes=highmem[01-02] MaxTime=7-00:00:00 State=UP
PartitionName=gpu      Nodes=gpu[01-08] MaxTime=2-00:00:00 State=UP
PartitionName=debug    Nodes=cpu[01-02] MaxTime=4:00:00 DefaultTime=1:00:00 State=UP

#------------------------------------------------------------------------------
# GRES (Generic Resources) - GPU Configuration
#------------------------------------------------------------------------------
# Note: Also requires /etc/slurm/gres.conf with:
#   NodeName=gpu[01-08] Name=gpu Type=a100 File=/dev/nvidia[0-3]
